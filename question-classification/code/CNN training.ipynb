{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipdb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-77b763afab3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipdb'"
     ]
    }
   ],
   "source": [
    "# Dont forget to:\n",
    "# - create a directory called \"cnn_models\" in the directory from where this code is executed\n",
    "# - put the preprocessed training data in a directory structure of \"/data/pre_processed/\"\n",
    "# - put the preprocessed test data in a directory structure of \"/data/test_pre_processed/\"\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dataset import Dataset  # import custom dataloaer\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from CNNText import CNNText\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_path = \"../data/pre_processed/\"\n",
    "train_dataset = Dataset(processed_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_path = \"../data/test_pre_processed/\"\n",
    "test_dataset = Dataset(processed_train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "n_epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "kernel_num = 3\n",
    "kernel_sizes = [2, 3, 4]\n",
    "dropout = 0.5\n",
    "\n",
    "cnn_classifier = CNNText(\n",
    "    embed_dim=768,\n",
    "    embed_num=512,\n",
    "    class_num=6,\n",
    "    kernel_num=kernel_num,\n",
    "    kernel_sizes=kernel_sizes,\n",
    "    dropout=dropout\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn_classifier.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnn_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltsin(ax, x_train, x_test, y_train, y_test, ydatacolors=['b','r']):\n",
    "    y = np.random.random(size=(100,1))\n",
    "    ax.plot(x_train, y_train, ydatacolors[0])\n",
    "    ax.plot(x_test, y_test, ydatacolors[1])\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(output, targets):\n",
    "    _, indices = output.max(1)\n",
    "    accuracy = sum(indices == targets)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('iteration #')\n",
    "ax.set_ylabel('loss')\n",
    "\n",
    "# to keep track of train and test performance for the plot\n",
    "train_plot_x, train_plot_y, test_plot_x, test_plot_y  = [], [], [], []\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0\n",
    "    print(f\"Current epoch {epoch} out of {n_epochs} \")\n",
    "    for file_index in range(len(train_dataset)):\n",
    "        iteration += 1\n",
    "\n",
    "        # retrieve batch input and targets\n",
    "        batch, labels = train_dataset[file_index]\n",
    "        _, targets = labels.max(1)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        cnn_classifier.train()\n",
    "\n",
    "        output = cnn_classifier(batch.float().to(device))    \n",
    "        loss = loss_fn(output, targets.to(device))\n",
    "        \n",
    "        train_plot_x.append(iteration)\n",
    "        train_plot_y.append(loss.detach().cpu())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # evaluate performance after every 5th epoch\n",
    "        if not file_index % 5:\n",
    "            cnn_classifier.eval()\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            for test_index in range(len(test_dataset)):\n",
    "                test_batch, test_labels = test_dataset[test_index]\n",
    "                _, test_indices = test_labels.max(1)\n",
    "                output = cnn_classifier(test_batch.float().to(device))\n",
    "\n",
    "                loss = loss_fn(output, test_indices.to(device))\n",
    "                test_loss += loss.detach().cpu()\n",
    "                \n",
    "                accuracy += get_accuracy(output.detach().cpu(), test_indices.cpu()).item()\n",
    "            \n",
    "            test_plot_x.append(iteration)\n",
    "            test_plot_y.append(test_loss/(len(test_dataset)))\n",
    "            cnn_classifier.train()\n",
    "\n",
    "\n",
    "        print(f'Epoch: [{epoch}/{n_epochs}] batch: [{file_index}/{len(train_dataset)}] Train loss: {loss} Validation loss: {test_loss/(len(test_dataset))} Validation accuracy {accuracy/(len(test_dataset))}')\n",
    "        pltsin(ax, train_plot_x, test_plot_x, train_plot_y, test_plot_y, ['b', 'r'])\n",
    "    torch.save(cnn_classifier.state_dict(), f\"cnn_models/model_epoch_{epoch}.p\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import CrossLingualPipeline\n",
    "from embedding_transform import EmbeddingTransform\n",
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "from polyglot.text import Text, Word\n",
    "\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0387,  0.0190, -0.0389,  ..., -0.0169,  0.0071,  0.0140],\n",
      "        [ 0.0182, -0.0076, -0.0458,  ...,  0.0136, -0.0478,  0.0276],\n",
      "        [-0.0543,  0.0137, -0.0304,  ...,  0.0157,  0.0138,  0.0279],\n",
      "        ...,\n",
      "        [-0.0308, -0.0389, -0.0065,  ...,  0.0234, -0.0996, -0.0930],\n",
      "        [ 0.0111,  0.0122, -0.0078,  ...,  0.0577,  0.0228,  0.0220],\n",
      "        [-0.0151, -0.0021,  0.0178,  ..., -0.0915, -0.0087, -0.0583]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[ 4.8135e+00, -8.6678e-01,  3.6377e+00,  ..., -4.6529e-01,\n",
      "         -3.2410e+00,  3.6285e+00],\n",
      "        [ 3.0188e+00, -4.0099e+00, -1.1321e+00,  ..., -2.9722e-03,\n",
      "          8.8285e-01, -8.8524e-01],\n",
      "        [ 5.0889e+00, -3.6843e+00,  2.7232e-01,  ...,  4.5834e+00,\n",
      "          2.3636e-01,  6.2977e+00],\n",
      "        ...,\n",
      "        [ 2.4421e+00, -1.2345e+00,  2.1860e+00,  ...,  1.8400e+00,\n",
      "         -6.5496e-01,  2.2318e+00],\n",
      "        [ 1.3630e+00,  4.5072e-01,  6.1568e-01,  ..., -5.0532e-01,\n",
      "         -5.5674e-02,  1.6714e+00],\n",
      "        [ 4.8724e-01,  9.4119e-01, -4.6929e-01,  ..., -1.6610e+00,\n",
      "         -7.8603e-01,  2.0104e+00]])\n",
      "epoch: 0 loss: 19.16757583618164\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EmbeddingTransform' object has no attribute 'eval_sgd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d23cc602de85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossLingualPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_sgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Developer/Projects/nlp2-transer-learning/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, transform_type, save_fn, transform_subset, eval_sgd)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mnl_words_to_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbeddingTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdutch_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menglish_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnl_words_to_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_words_to_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_tok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrt_tok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_tok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_tok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_sgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_sgd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Developer/Projects/nlp2-transer-learning/embedding_transform.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, transform_learning_method, source_embeddings, target_embeddings, nl_words_to_embed, en_words_to_embed, str_tok, end_tok, eval_sgd)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnl_words_to_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnl_words_to_embed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men_words_to_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_words_to_embed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr_tok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr_tok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_tok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_tok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Developer/Projects/nlp2-transer-learning/embedding_transform.py\u001b[0m in \u001b[0;36mlearn_transform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlearn_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_learning_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"SGD\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_transform_SGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_learning_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"SVD\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_transform_SVD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Developer/Projects/nlp2-transer-learning/embedding_transform.py\u001b[0m in \u001b[0;36mlearn_transform_SGD\u001b[0;34m(self, store_model_fn, load_model, train_ratio)\u001b[0m\n\u001b[1;32m    100\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch: {ep} loss: {tot_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_sgd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_prediction_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EmbeddingTransform' object has no attribute 'eval_sgd'"
     ]
    }
   ],
   "source": [
    "clpl = CrossLingualPipeline(eval_sgd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('venv': venv)",
   "language": "python",
   "name": "python37764bitvenvvenvadbe61290e6a49fe899ec2651f6f95c6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
